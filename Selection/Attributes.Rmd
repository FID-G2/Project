# Selección de atributos

## Imports necesarios

```{r}
#install.packages("ggplot2")
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("randomForest")
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(randomForest)
```

## 1. Funciones auxiliares

### 1.1. Reducción de la dimensionalidad generada por One-Hot encoding haciendo uso de PCA

En esta sección, se implementa la técnica de Análisis de Componentes Principales (PCA, por sus siglas en inglés) para reducir la dimensionalidad de las variables después de aplicar One-Hot Encoding. La dimensionalidad reducida facilita el manejo eficiente de los datos, disminuyendo la complejidad y el costo computacional en modelos de machine learning.

```{r}

reduce_dimensionality <- function(data, patterns, new_names) {
  if (length(patterns) != length(new_names)) {
    stop("Las listas de patrones y nombres nuevos deben tener la misma longitud")
  }

  for (i in seq_along(patterns)) {
    columns <- grepl(patterns[i], colnames(data))
    data_columns <- data[, columns]

    # Manejar datos faltantes
    data_columns <- na.omit(data_columns)

    # Escalar los datos
    data_columns <- scale(data_columns)

    # Realizar PCA con prcomp en lugar de princomp
    pca_result <- prcomp(data_columns, scale. = TRUE)

    # Seleccionar los primeros N componentes principales
    N <- min(ncol(data_columns), 3)  # Limitar a un máximo de 3 componentes
    pca_columns <- pca_result$x[, 1:N]

    new_column_names <- paste0(new_names[i], ".PCA", 1:N)

    data <- data[, !columns]
    data <- cbind(data, setNames(as.data.frame(pca_columns), new_column_names))
  }

  return(data)
}


```

```{r}
reduce_dimensionality <- function(data, patterns, new_names) {
  if (length(patterns) != length(new_names)) {
    stop("Las listas de patrones y nombres nuevos deben tener la misma longitud")
  }

  # Crear un dataframe vacío para almacenar los resultados temporales
  # Inicializar con el número máximo de componentes principales que esperas obtener
  temp_df <- data.frame(matrix(ncol = 4, nrow = 0))
  colnames(temp_df) <- c("Variable","PCA1", "PCA2", "PCA3")

  for (i in seq_along(patterns)) {
    columns <- grepl(patterns[i], colnames(data))
    data_columns <- data[, columns]

    # Manejar datos faltantes
    data_columns <- na.omit(data_columns)

    # Escalar los datos
    data_columns <- scale(data_columns)

    # Realizar PCA con prcomp en lugar de princomp
    pca_result <- prcomp(data_columns, scale. = TRUE)
    print(pca_result)
    print(colnames(pca_result$x))
    # Seleccionar los primeros N componentes principales
    N <- min(ncol(data_columns), 3)  # Limitar a un máximo de 3 componentes
    
    pca_columns <- pca_result$x[, 1:N]

    # Añadir los resultados de PCA al dataframe temporal
    temp_df <- rbind(temp_df,pca_result[,1:N])
  }

  # Exportar el dataframe temporal a un archivo CSV
  write.csv(temp_df, file = "temporal_dataframe.csv")

  return(data)
}

```

```{r}

reduce_dimensionality <- function(data, patterns, new_names) {
  if (length(patterns) != length(new_names)) {
    stop("Las listas de patrones y nombres nuevos deben tener la misma longitud")
  }

  # Crear un dataframe vacío con todas las posibles columnas
  all_column_names <- c( paste0(rep(new_names, each=3), ".PCA", rep(1:3, length(new_names))))
  temp_df <- data.frame(matrix(ncol = length(all_column_names), nrow = 0))
  colnames(temp_df) <- all_column_names

  for (i in seq_along(patterns)) {
    columns <- grepl(patterns[i], colnames(data))
    data_columns <- data[, columns]

    # Manejar datos faltantes
    data_columns <- na.omit(data_columns)

    # Escalar los datos
    data_columns <- scale(data_columns)

    # Realizar PCA con prcomp en lugar de princomp
    pca_result <- prcomp(data_columns, scale. = TRUE)

    # Seleccionar los primeros N componentes principales
    N <- min(ncol(data_columns), 3)  # Limitar a un máximo de 3 componentes
    pca_columns <- pca_result$x[, 1:N]

    new_column_names <- paste0(new_names[i], ".PCA", 1:N)

    # Añadir los resultados de PCA al dataframe temporal
    pca_df <- setNames(as.data.frame(t(pca_columns)), new_column_names)
    pca_df$Variable <- new_names[i]  # Añadir una columna con el nombre de la variable categórica

    # Asegurarse de que pca_df tiene todas las columnas necesarias
    missing_cols <- setdiff(colnames(temp_df), colnames(pca_df))
    pca_df[missing_cols] <- NA

    temp_df <- rbind(temp_df, pca_df)
  }

  # Exportar el dataframe temporal a un archivo CSV
  write.csv(temp_df, file = "temporal_dataframe.csv", row.names = FALSE)

  return(data)
}
```


## 2. Aplicación del proceso de selección de atributos

Lectura de los datos obtenidos tras aplicar el proceso de transformación.

```{r}

data <- read.csv("./data/CleanData/datos_transformados.csv")
```

Eliminar aquellas columnas que no aportan información al problema.

La razón detrás de la eliminación de las columnas "Número de Estudiantes", "Curso" y "Universidad" se basa en consideraciones específicas que afectan la calidad y la relevancia de los datos para el análisis y modelización

1.  **Número de Estudiantes:**

    -   La columna "Número de Estudiantes" fue eliminada debido a la presencia de valores iguales a cero cuando la zona de nacionalidad era diferente a España. Para lograr una mayor generalización y consideración de nacionalidades diversas, la eliminación de esta columna resultó más adecuada, permitiendo una representación más completa de los datos en relación con las diferentes nacionalidades.

2.  **Curso:**

    -   La columna "Curso" fue eliminada al decidir no tener en cuenta análisis de series temporales en el estudio. Al excluir esta variable temporal, se simplifica el conjunto de datos, enfocándolo en aspectos estáticos y facilitando la interpretación del modelo sin consideraciones temporales.

3.  **Universidad:**

    -   La columna "Universidad" fue eliminada debido a la limitada cantidad de datos disponibles para cada universidad específica. En lugar de modelar por universidad, se optó por generalizar a nivel de comunidad autónoma para asegurar una representación más robusta y evitar posibles sesgos causados por la escasez de datos por universidad.

```{r}

data <- data[, -which(names(data) == "Número.de.estudiantes")]
data <- data[, -which(names(data) == "Curso")]
data <- data %>% select(-starts_with("Universidad"))
```

Reducir la dimensionalidad generada tras haber realizado el proceso de One-Hot encoding.

```{r}
patterns <- c("^Comunidad", "^Rama", "^Ámbito", "^Zona.de.nacionalidad")
new_names <- c("Comunidad", "Rama", "Ámbito", "Zona.de.nacionalidad")
df_res <- reduce_dimensionality(data, patterns, new_names)
```

Redondear todos los atributos numéricos a dos decimales.

```{r}
# Redondear a 2 decimales todos los atributos numéricos
df_res <- df_res %>% mutate_if(is.numeric, round, 2)
```

Uso de Random Forest para ver la importancia de las distintas características con la columna "Nota media".

```{r}
set.seed(1234)
rf_model <- randomForest(Nota.media ~ ., data = df_res, ntree = 10, importance = TRUE)

print(importance(rf_model))
```

```{r}
# Gráfico de la importancia de los atributos
varImpPlot(rf_model)
```

## 5. Exportación de los datos resultantes a un fichero CSV

```{r}

nombre_archivo <- "../data/CleanData/datos_seleccion_atributos.csv"
write.csv(df_res, nombre_archivo, row.names = FALSE)
cat("Datos seleccionados y exportados a", nombre_archivo, "\n")
```
