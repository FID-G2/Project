# Modelo de regresión

## Imports necesarios

```{r}
#install.packages("caret")
#install.packages("rpart")
#install.packages("lightgbm")
#install.packages("randomForest")
#install.packages("r2r")
```

```{r}
library(randomForest)
library(caret)
library(rpart)
library(lightgbm)
library(r2r)
library(ggplot2)
```

## 1. Lectura de los datos

Lectura de los datos obtenidos tras aplicar el proceso de selección.

```{r}

df <- read.csv("../data/CleanData/datos_seleccion_atributos.csv")
control <- trainControl(method = "cv", number = 20)
```

## 2. Modelos

```{r}
#Código reutilizable
# Dividir el conjunto de datos en entrenamiento y prueba (80-20)
set.seed(123) 
index_entrenamiento <- createDataPartition(df$Nota.media, p = 0.8, list = FALSE)
datos_entrenamiento <- df[index_entrenamiento, ]
datos_prueba <- df[-index_entrenamiento, ]

```

### 2.1. Random Forest

#### 2.1.1. Entrenamiento con validación cruzada

```{r}

# 10 árboles
model_rf_10 <- train(Nota.media ~ ., data = df, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 10)

RMSE <- model_rf_10$results$RMSE
Rsquared <- model_rf_10$results$Rsquared
MAE <- model_rf_10$results$MAE
MSE <- RMSE^2

metrics_rf_10_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_10_cv[1]))
print(paste("R cuadrado:", metrics_rf_10_cv[2]))
print(paste("MAE:", metrics_rf_10_cv[3]))
print(paste("MSE:", metrics_rf_10_cv[4]))
```

```{r}
# 100 árboles
model_rf_100 <- train(Nota.media ~ ., data = df, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 100)

RMSE <- model_rf_100$results$RMSE
Rsquared <- model_rf_100$results$Rsquared
MAE <- model_rf_100$results$MAE
MSE <- RMSE^2

metrics_rf_100_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_100_cv[1]))
print(paste("R cuadrado:", metrics_rf_100_cv[2]))
print(paste("MAE:", metrics_rf_100_cv[3]))
print(paste("MSE:", metrics_rf_100_cv[4]))

```

```{r}
# 200 árboles
model_rf_200 <- train(Nota.media ~ ., data = df, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 200)

RMSE <- model_rf_200$results$RMSE
Rsquared <- model_rf_200$results$Rsquared
MAE <- model_rf_200$results$MAE
MSE <- RMSE^2

metrics_rf_200_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_200_cv[1]))
print(paste("R cuadrado:", metrics_rf_200_cv[2]))
print(paste("MAE:", metrics_rf_200_cv[3]))
print(paste("MSE:", metrics_rf_200_cv[4]))
```

#### 2.1.2. Entrenamiento con 80% de los datos y 20% para test

```{r}
# 10 árboles
model_rf_10_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 10)

# Realizar predicciones en el conjunto de prueba
predicciones_rf_10 <- predict(model_rf_10_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metricas <- postResample(predicciones_rf_10, datos_prueba$Nota.media)
RMSE <- unname(metricas["RMSE"])
Rsquared <- unname(metricas["Rsquared"])
MAE <- unname(metricas["MAE"])
MSE <- as.numeric(RMSE)^2

metrics_rf_10_alternative = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_10_alternative[1]))
print(paste("R cuadrado:", metrics_rf_10_alternative[2]))
print(paste("MAE:", metrics_rf_10_alternative[3]))
print(paste("MSE:", metrics_rf_10_alternative[4]))
```

```{r}
# 100 árboles
model_rf_100_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 100)

# Realizar predicciones en el conjunto de prueba
predicciones_rf_100 <- predict(model_rf_100_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metricas <- postResample(predicciones_rf_100, datos_prueba$Nota.media)
RMSE <- unname(metricas["RMSE"])
Rsquared <- unname(metricas["Rsquared"])
MAE <- unname(metricas["MAE"])
MSE <- as.numeric(RMSE)^2

metrics_rf_100_alternative = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_100_alternative[1]))
print(paste("R cuadrado:", metrics_rf_100_alternative[2]))
print(paste("MAE:", metrics_rf_100_alternative[3]))
print(paste("MSE:", metrics_rf_100_alternative[4]))
```

```{r}
# 200 árboles
model_rf_200_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 200)

# Realizar predicciones en el conjunto de prueba
predicciones_rf_200 <- predict(model_rf_200_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metricas <- postResample(predicciones_rf_200, datos_prueba$Nota.media)
RMSE <- unname(metricas["RMSE"])
Rsquared <- unname(metricas["Rsquared"])
MAE <- unname(metricas["MAE"])
MSE <- as.numeric(RMSE)^2

metrics_rf_200_alternative = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_200_alternative[1]))
print(paste("R cuadrado:", metrics_rf_200_alternative[2]))
print(paste("MAE:", metrics_rf_200_alternative[3]))
print(paste("MSE:", metrics_rf_200_alternative[4]))
```

### 2.2. LightGBM

#### 2.2.1. Entrenamiento de LightGBM con validación cruzada

```{r}

data <- as.matrix(df[, -which(names(df) == "Nota.media")])
label <- df$Nota.media

# Crear un conjunto de datos de LightGBM
lgb_data <- lgb.Dataset(data = data, label = label)
```

```{r}

#Learning rate = 0.01

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumentar el número de hojas en el árbol
  learning_rate = 0.01,  # Disminuir la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumentar la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuir el número mínimo de datos en una hoja
)


# Entrenar el modelo con validación cruzada
cv_results_001 <- lgb.cv(params,
                     data = lgb_data,
                     nrounds = 10,
                     nfold = 20,
                     verbose = 0)

# Mostrar los resultados
RMSE = sapply(cv_results_001$record_evals$valid$rmse$eval, min)
RMSE = min(RMSE)
MAE = sapply(cv_results_001$record_evals$valid$l1$eval, min)
MAE = min(MAE)
MSE = sapply(cv_results_001$record_evals$valid$l2$eval, min)
MSE = min(MSE)

metrics_lgb_001_cv = list(RMSE,MAE,MSE)

print(paste("RMSE:", metrics_lgb_001_cv[1]))
print(paste("MAE:", metrics_lgb_001_cv[2]))
print(paste("MSE:", metrics_lgb_001_cv[3]))
```

```{r}

#Learning rate = 0.05

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumentar el número de hojas en el árbol
  learning_rate = 0.05,  # Disminuir la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumentar la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuir el número mínimo de datos en una hoja
)


# Entrenar el modelo con validación cruzada
cv_results_005 <- lgb.cv(params,
                     data = lgb_data,
                     nrounds = 10,
                     nfold = 20,
                     verbose = 0)

# Mostrar los resultados
RMSE = sapply(cv_results_005$record_evals$valid$rmse$eval, min)
RMSE = min(RMSE)
MAE = sapply(cv_results_005$record_evals$valid$l1$eval, min)
MAE = min(MAE)
MSE = sapply(cv_results_005$record_evals$valid$l2$eval, min)
MSE = min(MSE)

metrics_lgb_005_cv = list(RMSE,MAE,MSE)

print(paste("RMSE:", metrics_lgb_005_cv[1]))
print(paste("MAE:", metrics_lgb_005_cv[2]))
print(paste("MSE:", metrics_lgb_005_cv[3]))
```

```{r}

#Learning rate = 0.1

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumentar el número de hojas en el árbol
  learning_rate = 0.1,  # Disminuir la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumentar la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuir el número mínimo de datos en una hoja
)


# Entrenar el modelo con validación cruzada
cv_results_010 <- lgb.cv(params,
                     data = lgb_data,
                     nrounds = 10,
                     nfold = 20,
                     verbose = 0)

# Mostrar los resultados
RMSE = sapply(cv_results_010$record_evals$valid$rmse$eval, min)
RMSE = min(RMSE)
MAE = sapply(cv_results_010$record_evals$valid$l1$eval, min)
MAE = min(MAE)
MSE = sapply(cv_results_010$record_evals$valid$l2$eval, min)
MSE = min(MSE)

metrics_lgb_010_cv = list(RMSE,MAE,MSE)

print(paste("RMSE:", metrics_lgb_010_cv[1]))
print(paste("MAE:", metrics_lgb_010_cv[2]))
print(paste("MSE:", metrics_lgb_010_cv[3]))
```

#### 2.2.2. Entrenamiento de LightGBM con 80% de los datos y 20% para test

```{r}

# Preparar los datos de entrenamiento y prueba para LightGBM
data_entrenamiento <- as.matrix(datos_entrenamiento[, -which(names(datos_entrenamiento) == "Nota.media")])
label_entrenamiento <- datos_entrenamiento$Nota.media
lgb_data_entrenamiento <- lgb.Dataset(data = data_entrenamiento, label = label_entrenamiento)

data_prueba <- as.matrix(datos_prueba[, -which(names(datos_prueba) == "Nota.media")])
label_prueba <- datos_prueba$Nota.media
lgb_data_prueba <- lgb.Dataset(data = data_prueba, label = label_prueba)
```

```{r}

# learning_rate = 0.01

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumenta el número de hojas en el árbol
  learning_rate = 0.01,  # Disminuye la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumenta la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuye el número mínimo de datos en una hoja
)


# Entrenar el modelo con LightGBM
model_lgb_001_alternative <- lgb.train(params,
                        data = lgb_data_entrenamiento,
                        nrounds = 10,
                        valids = list(valid = lgb_data_prueba),
                        early_stopping_rounds = 5,
                        verbose = 0)

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_lgbm <- predict(model_lgb_001_alternative, data_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metrics_lgb_001_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_lgbm - label_prueba)^2)),
  MAE = mean(abs(predicciones_prueba_lgbm - label_prueba)),
  MSE = mean((predicciones_prueba_lgbm - label_prueba)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_lgb_001_alternative[1]))
print(paste("MAE:", metrics_lgb_001_alternative[2]))
print(paste("MSE:", metrics_lgb_001_alternative[3]))
```

```{r}

# learning_rate = 0.05

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumenta el número de hojas en el árbol
  learning_rate = 0.05,  # Disminuye la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumenta la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuye el número mínimo de datos en una hoja
)


# Entrenar el modelo con LightGBM
model_lgb_005_alternative <- lgb.train(params,
                        data = lgb_data_entrenamiento,
                        nrounds = 10,
                        valids = list(valid = lgb_data_prueba),
                        early_stopping_rounds = 5,
                        verbose = 0)

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_lgbm <- predict(model_lgb_005_alternative, data_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metrics_lgb_005_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_lgbm - label_prueba)^2)),
  MAE = mean(abs(predicciones_prueba_lgbm - label_prueba)),
  MSE = mean((predicciones_prueba_lgbm - label_prueba)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_lgb_005_alternative[1]))
print(paste("MAE:", metrics_lgb_005_alternative[2]))
print(paste("MSE:", metrics_lgb_005_alternative[3]))
```

```{r}

# learning_rate = 0.1

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,
  learning_rate = 0.1,
  nthread = 4,
  max_depth = 4,
  min_data_in_leaf = 20
)


# Entrenar el modelo con LightGBM
model_lgb_010_alternative <- lgb.train(params,
                        data = lgb_data_entrenamiento,
                        nrounds = 10,
                        valids = list(valid = lgb_data_prueba),
                        early_stopping_rounds = 5,
                        verbose = 0)

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_lgbm <- predict(model_lgb_010_alternative, data_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metrics_lgb_010_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_lgbm - label_prueba)^2)),
  MAE = mean(abs(predicciones_prueba_lgbm - label_prueba)),
  MSE = mean((predicciones_prueba_lgbm - label_prueba)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_lgb_010_alternative[1]))
print(paste("MAE:", metrics_lgb_010_alternative[2]))
print(paste("MSE:", metrics_lgb_010_alternative[3]))
```

### 2.3. Decision Tree

#### 2.3.1. Entrenamiento de Decision Tree con validación cruzada

```{r}

# cp = 0.1

model_tree_010 <- train(Nota.media ~ ., data = df, method = "rpart", trControl = control, control = rpart.control(cp = 0.1))

RMSE <- min(model_tree_010$results$RMSE)
Rsquared <- min(model_tree_010$results$Rsquared)
MAE <- min(model_tree_010$results$MAE)
MSE <- RMSE^2

metrics_tree_010_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_tree_010_cv[1]))
print(paste("R cuadrado:", metrics_tree_010_cv[2]))
print(paste("MAE:", metrics_tree_010_cv[3]))
print(paste("MSE:", metrics_tree_010_cv[4]))
```

```{r}

# cp = 0.2

model_tree_020 <- train(Nota.media ~ ., data = df, method = "rpart", trControl = control, control = rpart.control(cp = 0.2))

RMSE <- min(model_tree_020$results$RMSE)
Rsquared <- min(model_tree_020$results$Rsquared)
MAE <- min(model_tree_020$results$MAE)
MSE <- RMSE^2

metrics_tree_020_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_tree_020_cv[1]))
print(paste("R cuadrado:", metrics_tree_020_cv[2]))
print(paste("MAE:", metrics_tree_020_cv[3]))
print(paste("MSE:", metrics_tree_020_cv[4]))
```

```{r}

# cp = 0.5

model_tree_050 <- train(Nota.media ~ ., data = df, method = "rpart", trControl = control, control = rpart.control(cp = 0.5))

RMSE <- min(model_tree_050$results$RMSE)
Rsquared <- min(model_tree_050$results$Rsquared)
MAE <- min(model_tree_050$results$MAE)
MSE <- RMSE^2

metrics_tree_050_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_tree_050_cv[1]))
print(paste("R cuadrado:", metrics_tree_050_cv[2]))
print(paste("MAE:", metrics_tree_050_cv[3]))
print(paste("MSE:", metrics_tree_050_cv[4]))
```

#### 2.3.2. Entrenamiento de Decision Tree con 80% de los datos para entrenamiento y 20% para test

```{r}

# cp = 0.1

# Entrenar el modelo de árbol de decisión
model_tree_010_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rpart", trControl = control, control = rpart.control(cp = 0.1))

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_tree <- predict(model_tree_010_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba

# Primero, calculamos la suma total de los cuadrados (SST)
sst <- sum((datos_prueba$Nota.media - mean(datos_prueba$Nota.media))^2)

# Luego, calculamos la suma de los cuadrados de los residuos (SSR)
ssr <- sum((predicciones_prueba_tree - datos_prueba$Nota.media)^2)

metrics_tree_010_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)),
  R_Cuadrado = 1 - (ssr / sst),
  MAE = mean(abs(predicciones_prueba_tree - datos_prueba$Nota.media)),
  MSE = mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_tree_010_alternative[1]))
print(paste("R cuadrado:", metrics_tree_010_alternative[2]))
print(paste("MAE:", metrics_tree_010_alternative[3]))
print(paste("MSE:", metrics_tree_010_alternative[4]))
```

```{r}

# cp = 0.2

# Entrenar el modelo de árbol de decisión
model_tree_020_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rpart", trControl = control, control = rpart.control(cp = 0.2))

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_tree <- predict(model_tree_020_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba

# Primero, calculamos la suma total de los cuadrados (SST)
sst <- sum((datos_prueba$Nota.media - mean(datos_prueba$Nota.media))^2)

# Luego, calculamos la suma de los cuadrados de los residuos (SSR)
ssr <- sum((predicciones_prueba_tree - datos_prueba$Nota.media)^2)

metrics_tree_020_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)),
  R_Cuadrado = 1 - (ssr / sst),
  MAE = mean(abs(predicciones_prueba_tree - datos_prueba$Nota.media)),
  MSE = mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_tree_020_alternative[1]))
print(paste("R cuadrado:", metrics_tree_020_alternative[2]))
print(paste("MAE:", metrics_tree_020_alternative[3]))
print(paste("MSE:", metrics_tree_020_alternative[4]))
```

```{r}

# cp = 0.5

# Entrenar el modelo de árbol de decisión
model_tree_050_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rpart", trControl = control, control = rpart.control(cp = 0.5))

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_tree <- predict(model_tree_050_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba

# Primero, calculamos la suma total de los cuadrados (SST)
sst <- sum((datos_prueba$Nota.media - mean(datos_prueba$Nota.media))^2)

# Luego, calculamos la suma de los cuadrados de los residuos (SSR)
ssr <- sum((predicciones_prueba_tree - datos_prueba$Nota.media)^2)

metrics_tree_050_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)),
  R_Cuadrado = 1 - (ssr / sst),
  MAE = mean(abs(predicciones_prueba_tree - datos_prueba$Nota.media)),
  MSE = mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_tree_050_alternative[1]))
print(paste("R cuadrado:", metrics_tree_050_alternative[2]))
print(paste("MAE:", metrics_tree_050_alternative[3]))
print(paste("MSE:", metrics_tree_050_alternative[4]))
```

### 2.4. Comparación de los modelos

#### 2.4.1. Comparación de los modelos que obtienen menor error con validación cruzada

```{r}
metricas_df_cv <- data.frame(
  Modelo = c(rep("Random Forest (200 árboles)", 4), rep("Decision Tree (cp=0.5)", 4), rep("LightGBM (lr=0.1)", 4)),
  Metrica = rep(c("RMSE", "MSE", "MAE", "R cuadrado"), 3),
  valor = c(
    as.numeric(metrics_rf_200_cv[1]),
    as.numeric(metrics_rf_200_cv[4]),
    as.numeric(metrics_rf_200_cv[3]),
    as.numeric(metrics_rf_200_cv[2]),
    as.numeric(metrics_tree_050_cv[1]),
    as.numeric(metrics_tree_050_cv[4]),
    as.numeric(metrics_tree_050_cv[3]),
    as.numeric(metrics_tree_050_cv[2]),
    as.numeric(metrics_lgb_010_cv[1]),
    as.numeric(metrics_lgb_010_cv[3]),
    as.numeric(metrics_lgb_010_cv[2]),
    0
  ),
  Tipo = rep("Validación cruzada", 12)
)

# Crear la gráfica
ggplot(metricas_df_cv, aes(x = Modelo, y = valor, fill = Metrica)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Rendimiento del Modelo",
       y = "Valor de Métrica",
       x = "Modelo",
       fill = "Métrica") +
  theme_minimal()
```

#### 2.4.2. Comparación de los modelos con 80% de los datos para entrenamiento y 20% para test

```{r}

# Crear un dataframe con las métricas y el tipo de modelo
metricas_df_alternative <- data.frame(
  Modelo = c(rep("Random Forest (200 árboles)", 4), rep("Decision Tree (cp=0.5)", 4), rep("LightGBM (lr=0.1)", 4)),
  Metrica = rep(c("RMSE", "MSE", "MAE", "R cuadrado"), 3),
  valor = c(
    as.numeric(metrics_rf_200_alternative[1]),
    as.numeric(metrics_rf_200_alternative[4]),
    as.numeric(metrics_rf_200_alternative[3]),
    as.numeric(metrics_rf_200_alternative[2]),
    as.numeric(metrics_tree_050_alternative[1]),
    as.numeric(metrics_tree_050_alternative[4]),
    as.numeric(metrics_tree_050_alternative[3]),
    as.numeric(metrics_tree_050_alternative[2]),
    as.numeric(metrics_lgb_010_alternative[1]),
    as.numeric(metrics_lgb_010_alternative[3]),
    as.numeric(metrics_lgb_010_alternative[2]),
    0
  ),
  Tipo = rep("Hold-out", 12)
)

# Crear la gráfica
ggplot(metricas_df_alternative, aes(x = Modelo, y = valor, fill = Metrica)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Rendimiento del Modelo en Conjunto de Pruebas",
       y = "Valor de Métrica",
       x = "Modelo",
       fill = "Métrica") +
  theme_minimal()

```

#### 2.4.3. Comparación del uso de validación cruzada frente a *Hold-out*

```{r}

metricas_res <- rbind(metricas_df_cv, metricas_df_alternative)

# Crear la gráfica
ggplot(metricas_res, aes(x = Modelo, y = valor, fill = Tipo)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~Metrica) +
  labs(title = "Rendimiento del Modelo",
       y = "Valor de Métrica",
       x = "Modelo",
       fill = "Tipo") +
  theme_minimal()
```

## 3. Predicción sobre modelos

### 3.1. Dataframe auxiliar de PCAs

```{r}

data <- read.csv("../data/CleanData/var_PCAs.csv")
head(data)
```

### 3.2. Hashes auxiliares

Estos hashes definidos se utilizan para asociar el valor de una columna que inserta el usuario, por ejemplo "Andalucia" en comunidad autómona, con el valor de la columna para nuestro caso tras los distintos cambios en el dataset, por ejemplo, "Comunidad.AutónomaAndalucía" para "Andalucia".

```{r}

claves_comunidades <- c("Andalucía","Aragón", "Asturias", "Cantabria", "Castilla y León", "Cataluña", "Extremadura", "Galicia", "La Rioja", "Madrid", "Murcia", "Navarra", "País Vasco")

valores_comunidades <- c("Comunidad.AutónomaAndalucía","Comunidad.AutónomaAragón", "Comunidad.AutónomaAsturias", "Comunidad.AutónomaCantabria", "Comunidad.AutónomaCastilla.y.León", "Comunidad.AutónomaCataluña", "Comunidad.AutónomaExtremadura", "Comunidad.AutónomaGalicia", "Comunidad.AutónomaLa.Rioja", "Comunidad.AutónomaMadrid", "Comunidad.AutónomaMurcia", "Comunidad.AutónomaNavarra", "Comunidad.AutónomaPaís.Vasco")

comunidades <- hashmap()
comunidades[claves_comunidades] <- valores_comunidades

claves_ramas_enseñanza <- c("Artes y Humanidades", "Ciencias", "Ciencias de la Salud", "Ciencias Sociales y Jurídicas", "Ingeniería y Arquitectura")

valores_ramas_enseñanza <- c("Rama.de.enseñanzaArtes.y.Humanidades","Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaIngeniería.y.Arquitectura")

ramas_enseñanza <- hashmap()
ramas_enseñanza[claves_ramas_enseñanza] <- valores_ramas_enseñanza

claves_ambitos_estudio <- c("Arquitectura y construcción", "Artes", "Ciencias de la vida", "Ciencias Físicas, químicas, geológicas", "Derecho", "Economía", "Enfermería y atención a enfermos", "Humanidades", "Informática", "Ingenierías", "Lenguas", "Medicina", "Periodismo e información", "Trabajo social y orientación")

valores_ambitos_estudio <- c("Ámbito.de.estudioArquitectura.y.construcción", "Ámbito.de.estudioArtes", "Ámbito.de.estudioCiencias.de.la.vida", "Ámbito.de.estudioCiencias.Físicas..químicas..geológicas", "Ámbito.de.estudioDerecho", "Ámbito.de.estudioEconomía", "Ámbito.de.estudioEnfermería.y.atención.a.enfermos", "Ámbito.de.estudioHumanidades", "Ámbito.de.estudioInformática", "Ámbito.de.estudioIngenierías", "Ámbito.de.estudioLenguas", "Ámbito.de.estudioMedicina", "Ámbito.de.estudioPeriodismo.e.información", "Ámbito.de.estudioTrabajo.social.y.orientación")
  
ambitos_estudio <- hashmap()
ambitos_estudio[claves_ambitos_estudio] <- valores_ambitos_estudio

valores_ambitos_estudio_ramas_enseñanza <- c("Rama.de.enseñanzaIngeniería.y.Arquitectura", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaIngeniería.y.Arquitectura", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas")

ambitos_estudio_ramas_enseñanza <- hashmap()
ambitos_estudio_ramas_enseñanza[valores_ambitos_estudio] <- valores_ambitos_estudio_ramas_enseñanza

claves_zonas_nacionalidad <- c("Asia y Oceanía", "EEUU y Canadá", "España", "Norte de África", "Resto de África", "Resto de Europa", "Unión Europea")

valores_zonas_nacionalidad <- c("Zona.de.nacionalidadAsia.y.Oceanía", "Zona.de.nacionalidadEEUU.y.Canadá", "Zona.de.nacionalidadEspaña", "Zona.de.nacionalidadNorte.de.África", "Zona.de.nacionalidadResto.de.África", "Zona.de.nacionalidadResto.de.Europa", "Zona.de.nacionalidadUnión.Europea")

zonas_nacionalidad <- hashmap()
zonas_nacionalidad[claves_zonas_nacionalidad] <- valores_zonas_nacionalidad


```

### 3.3. Funciones auxiliares

```{r}

binary_encode <- function(data, variable, category1, category2) {
  # Crear una nueva columna con la codificación binaria
  data[[variable]] <- ifelse(data[[variable]] == category1, 0, 1)

  # Devolver el conjunto de datos modificado
  return(data)
}
```

La siguiente función se utiliza para agregar las componentes PCA para el valor de una columna al dataframe.

```{r}

agregar_datos_pca <- function(data, df_indices, nombre_columna, prefijo_pca) {

  # Obtener el nombre de la columna y la fila correspondiente
  valor <- data[[nombre_columna]]
  fila <- df_indices[df_indices$Variable == valor, ]

  # Verificar si se encontró la fila
  if (nrow(fila) > 0) {
    # Extraer los valores de PCA de la fila
    valores_pca <- fila[, grepl("^PCA", colnames(fila))]

    colnames(valores_pca) <- paste0(prefijo_pca, colnames(valores_pca))

    # Agregar las columnas de PCA al dataframe de datos
    data_con_pca <- cbind(data, valores_pca)
    
    data_con_pca <- data_con_pca[, !colnames(data_con_pca) %in% nombre_columna, drop = FALSE]

    return(data_con_pca)
  } else {
    cat("No se encontró la fila correspondiente para el valor:", valor, "\n")
    return(NULL)
  }
}
```

La siguiente función es utilizada para transforma una entrada dada por el usuario al formato necesario para realizar la predicción.

```{r}

adaptar_dataframe <- function(df){
  
  df_nivel <- binary_encode(df, "Forma.de.admisión", "PAU", "FP")
  
  if(!has_key(comunidades, df_nivel$Comunidad.Autónoma)){
    cat("Posibles valores para Comunidad.Autónoma:", paste(keys(comunidades), collapse = ", "))
    stop("Asígnele un valor válido a Comunidad.Autónoma")
  }
  df_nivel$Comunidad.Autónoma <- comunidades[df_nivel$Comunidad.Autónoma]
  
  if (!has_key(ambitos_estudio, df_nivel$Ámbito.de.estudio)) {
    cat("Posibles valores para Ámbito.de.estudio:", paste(keys(ambitos_estudio), collapse = ", "))
    stop("Asígnele un valor válido a Ámbito.de.estudio")
  }
  df_nivel$Ámbito.de.estudio <- ambitos_estudio[[df_nivel$Ámbito.de.estudio]]
  df_nivel$Rama.de.enseñanza <- ambitos_estudio_ramas_enseñanza[[df_nivel$Ámbito.de.estudio]]
  
  if (!has_key(zonas_nacionalidad, df_nivel$Zona.de.nacionalidad)) {
    cat("Posibles valores para Zona.de.nacionalidad:", paste(keys(zonas_nacionalidad), collapse = ", "))
    stop("Asígnele un valor válido a Zona.de.nacionalidad")
  }
  df_nivel$Zona.de.nacionalidad <- zonas_nacionalidad[[df_nivel$Zona.de.nacionalidad]]

  df_pca_comunidad <- agregar_datos_pca(df_nivel, data, "Comunidad.Autónoma", "Comunidad.")
  df_pca_rama_enseñanza <- agregar_datos_pca(df_pca_comunidad, data, "Rama.de.enseñanza", "Rama.")
  df_pca_ambito_estudio <- agregar_datos_pca(df_pca_rama_enseñanza, data, "Ámbito.de.estudio", "Ámbito.")
  df_pca_zona_nacionalidad <- agregar_datos_pca(df_pca_ambito_estudio, data, "Zona.de.nacionalidad", "Zona.de.nacionalidad.")
  
  return(df_pca_zona_nacionalidad)
}
```

### 3.4. Input del usuario

```{r}
nuevos_datos_rf <- data.frame(
    Comunidad.Autónoma = "Andalucía",
    Forma.de.admisión = "PAU",
    Ámbito.de.estudio = "Economía",
    Zona.de.nacionalidad = "España"
)

head(nuevos_datos_rf)
```

```{r}

df_prediccion <- adaptar_dataframe(nuevos_datos_rf)
head(df_prediccion)
```

### 3.5. Predicciones sobre modelos entrenados con validación cruzada

#### 3.5.1. Predicciones sobre Random Forest

```{r}

predicciones <- predict(model_rf_200, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

#### 3.5.2. Predicciones sobre Decision Tree

```{r}

predicciones <- predict(model_tree_050, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

### 3.6. Predicciones sobre modelos entrenados con partición de datos 80/20

#### 3.6.1. Predicciones sobre Random Forest

```{r}

predicciones <- predict(model_rf_200_alternative, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

#### 3.6.2. Predicciones sobre Decision Tree

```{r}

predicciones <- predict(model_tree_050_alternative, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)

```

#### 3.6.1. Predicciones sobre LightLGB

```{r}

data_prediction <- as.matrix(df_prediccion)
predicciones <- predict(model_lgb_010_alternative, data_prediction)


print(predicciones[1]*14)
```
