# Modelo de regresión

## Imports necesarios

```{r}
#install.packages("caret")
#install.packages("rpart")
#install.packages("lightgbm")
#install.packages("randomForest")
#install.packages("r2r")
```

```{r}
library(randomForest)
library(caret)
library(rpart)
library(lightgbm)
library(r2r)
library(ggplot2)
```

## 1. Lectura de los datos

Lectura de los datos obtenidos tras aplicar el proceso de selección.

```{r}

df <- read.csv("../data/CleanData/datos_seleccion_atributos.csv")
control <- trainControl(method = "cv", number = 20)
```

## 2. Modelos

```{r}
#Código reutilizable
# Dividir el conjunto de datos en entrenamiento y prueba (80-20)
set.seed(123) 
index_entrenamiento <- createDataPartition(df$Nota.media, p = 0.8, list = FALSE)
datos_entrenamiento <- df[index_entrenamiento, ]
datos_prueba <- df[-index_entrenamiento, ]

```

### 2.1. Random Forest

#### 2.1.1. Entrenamiento con validación cruzada

```{r}

model_rf <- train(Nota.media ~ ., data = df, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 200)

RMSE <- model_rf$results$RMSE
Rsquared <- model_rf$results$Rsquared
MAE <- model_rf$results$MAE
MSE <- RMSE^2

metrics_rf_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_cv[1]))
print(paste("R cuadrado:", metrics_rf_cv[2]))
print(paste("MAE:", metrics_rf_cv[3]))
print(paste("MSE:", metrics_rf_cv[4]))
```

#### 2.1.2. Entrenamiento con 80% de los datos y 20% para test

```{r}
model_rf_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rf", trControl = control, tuneGrid = data.frame(mtry = 2), ntree = 200)
```

```{r}
# Realizar predicciones en el conjunto de prueba
predicciones_rf <- predict(model_rf_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metricas <- postResample(predicciones_rf, datos_prueba$Nota.media)
RMSE <- unname(metricas["RMSE"])
Rsquared <- unname(metricas["Rsquared"])
MAE <- unname(metricas["MAE"])
MSE <- as.numeric(RMSE)^2

metrics_rf_alternative = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_rf_alternative[1]))
print(paste("R cuadrado:", metrics_rf_alternative[2]))
print(paste("MAE:", metrics_rf_alternative[3]))
print(paste("MSE:", metrics_rf_alternative[4]))
```

### 2.2. LightGBM

#### 2.2.1. Entrenamiento de LightGBM con validación cruzada

```{r}

data <- as.matrix(df[, -which(names(df) == "Nota.media")])
label <- df$Nota.media

# Crear un conjunto de datos de LightGBM
lgb_data <- lgb.Dataset(data = data, label = label)

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumenta el número de hojas en el árbol
  learning_rate = 0.01,  # Disminuye la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumenta la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuye el número mínimo de datos en una hoja
)


# Entrenar el modelo con validación cruzada
cv_results <- lgb.cv(params,
                     data = lgb_data,
                     nrounds = 10,
                     nfold = 20,
                     verbose = 0)

# Mostrar los resultados
RMSE = sapply(cv_results$record_evals$valid$rmse$eval, min)
RMSE = min(RMSE)
MAE = sapply(cv_results$record_evals$valid$l1$eval, min)
MAE = min(MAE)
MSE = sapply(cv_results$record_evals$valid$l2$eval, min)
MSE = min(MSE)

metrics_lgb_cv = list(RMSE,MAE,MSE)

print(paste("RMSE:", metrics_lgb_cv[1]))
print(paste("MAE:", metrics_lgb_cv[2]))
print(paste("MSE:", metrics_lgb_cv[3]))
```

#### 2.2.2. Entrenamiento de LightGBM con 80% de los datos y 20% para test

```{r}
# Preparar los datos de entrenamiento y prueba para LightGBM
data_entrenamiento <- as.matrix(datos_entrenamiento[, -which(names(datos_entrenamiento) == "Nota.media")])
label_entrenamiento <- datos_entrenamiento$Nota.media
lgb_data_entrenamiento <- lgb.Dataset(data = data_entrenamiento, label = label_entrenamiento)

data_prueba <- as.matrix(datos_prueba[, -which(names(datos_prueba) == "Nota.media")])
label_prueba <- datos_prueba$Nota.media
lgb_data_prueba <- lgb.Dataset(data = data_prueba, label = label_prueba)

# Especificar los parámetros del modelo
params <- list(
  objective = "regression",
  metric = list("rmse","mse", "mae"), 
  num_leaves = 120,  # Aumenta el número de hojas en el árbol
  learning_rate = 0.01,  # Disminuye la tasa de aprendizaje
  nthread = 4,
  max_depth = 4,  # Aumenta la profundidad máxima del árbol
  min_data_in_leaf = 20  # Disminuye el número mínimo de datos en una hoja
)


# Entrenar el modelo con LightGBM
model_lgb_alternative <- lgb.train(params,
                        data = lgb_data_entrenamiento,
                        nrounds = 10,
                        valids = list(valid = lgb_data_prueba),
                        early_stopping_rounds = 5,
                        verbose = 0)

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_lgbm <- predict(model_lgb_alternative, data_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba
metrics_lgb_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_lgbm - label_prueba)^2)),
  MAE = mean(abs(predicciones_prueba_lgbm - label_prueba)),
  MSE = mean((predicciones_prueba_lgbm - label_prueba)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_lgb_alternative[1]))
print(paste("MAE:", metrics_lgb_alternative[2]))
print(paste("MSE:", metrics_lgb_alternative[3]))
```

### 2.3. Decision Tree

#### 2.3.1. Entrenamiento de Decision Tree con validación cruzada

```{r}

model_tree <- train(Nota.media ~ ., data = df, method = "rpart", trControl = control, control = rpart.control(cp = 0.01))

RMSE <- min(model_tree$results$RMSE)
Rsquared <- min(model_tree$results$Rsquared)
MAE <- min(model_tree$results$MAE)
MSE <- RMSE^2

metrics_tree_cv = list(RMSE,Rsquared,MAE,MSE)

print(paste("RMSE:", metrics_tree_cv[1]))
print(paste("R cuadrado:", metrics_tree_cv[2]))
print(paste("MAE:", metrics_tree_cv[3]))
print(paste("MSE:", metrics_tree_cv[4]))
```

#### 2.3.2. Entrenamiento de Decision Tree con 80% de los datos para entrenamiento y 20% para test

```{r}
# Entrenar el modelo de árbol de decisión
model_tree_alternative <- train(Nota.media ~ ., data = datos_entrenamiento, method = "rpart", trControl = control, control = rpart.control(cp = 0.1))

# Realizar predicciones en el conjunto de prueba
predicciones_prueba_tree <- predict(model_tree_alternative, newdata = datos_prueba)

# Evaluar el rendimiento del modelo en el conjunto de prueba

# Primero, calculamos la suma total de los cuadrados (SST)
sst <- sum((datos_prueba$Nota.media - mean(datos_prueba$Nota.media))^2)

# Luego, calculamos la suma de los cuadrados de los residuos (SSR)
ssr <- sum((predicciones_prueba_tree - datos_prueba$Nota.media)^2)

metrics_tree_alternative <- list(
  RMSE = sqrt(mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)),
  R_Cuadrado = 1 - (ssr / sst),
  MAE = mean(abs(predicciones_prueba_tree - datos_prueba$Nota.media)),
  MSE = mean((predicciones_prueba_tree - datos_prueba$Nota.media)^2)
)

# Mostrar las métricas en el conjunto de prueba
print(paste("RMSE:", metrics_tree_alternative[1]))
print(paste("R cuadrado:", metrics_tree_alternative[2]))
print(paste("MAE:", metrics_tree_alternative[3]))
print(paste("MSE:", metrics_tree_alternative[4]))
```

### 2.4. Comparación de los modelos

#### 2.4.1. Comparación de los modelos con validación cruzada

```{r}
metricas_df_cv <- data.frame(
  Modelo = c(rep("Random Forest", 4), rep("Decision Tree", 4), rep("LightGBM", 4)),
  Metrica = rep(c("RMSE", "MSE", "MAE", "R cuadrado"), 3),
  valor = c(
    as.numeric(metrics_rf_cv[1]),
    as.numeric(metrics_rf_cv[4]),
    as.numeric(metrics_rf_cv[3]),
    as.numeric(metrics_rf_cv[2]),
    as.numeric(metrics_tree_cv[1]),
    as.numeric(metrics_tree_cv[4]),
    as.numeric(metrics_tree_cv[3]),
    as.numeric(metrics_tree_cv[2]),
    as.numeric(metrics_lgb_cv[1]),
    as.numeric(metrics_lgb_cv[3]),
    as.numeric(metrics_lgb_cv[2]),
    0
  )
)

# Crear la gráfica
ggplot(metricas_df_cv, aes(x = Modelo, y = valor, fill = Metrica)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Rendimiento del Modelo en Conjunto de Pruebas",
       y = "Valor de Métrica",
       x = "Modelo",
       fill = "Métrica") +
  theme_minimal()
```

#### 2.4.2. Comparación de los modelos con 80% de los datos para entrenamiento y 20% para test

```{r}

# Crear un dataframe con las métricas y el tipo de modelo
metricas_df_alternative <- data.frame(
  Modelo = c(rep("Random Forest", 4), rep("Decision Tree", 4), rep("LightGBM", 4)),
  Metrica = rep(c("RMSE", "MSE", "MAE", "R cuadrado"), 3),
  valor = c(
    as.numeric(metrics_rf_alternative[1]),
    as.numeric(metrics_rf_alternative[4]),
    as.numeric(metrics_rf_alternative[3]),
    as.numeric(metrics_rf_alternative[2]),
    as.numeric(metrics_tree_alternative[1]),
    as.numeric(metrics_tree_alternative[4]),
    as.numeric(metrics_tree_alternative[3]),
    as.numeric(metrics_tree_alternative[2]),
    as.numeric(metrics_lgb_alternative[1]),
    as.numeric(metrics_lgb_alternative[3]),
    as.numeric(metrics_lgb_alternative[2]),
    0
  )
)

# Crear la gráfica
ggplot(metricas_df_alternative, aes(x = Modelo, y = valor, fill = Metrica)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Rendimiento del Modelo en Conjunto de Pruebas",
       y = "Valor de Métrica",
       x = "Modelo",
       fill = "Métrica") +
  theme_minimal()

```

## 3. Predicción sobre modelos

### 3.1. Dataframe auxiliar de PCAs

```{r}

data <- read.csv("../data/CleanData/var_PCAs.csv")
head(data)
```

### 3.2. Hashes auxiliares

```{r}

claves_comunidades <- c("Andalucía","Aragón", "Asturias", "Cantabria", "Castilla y León", "Cataluña", "Extremadura", "Galicia", "La Rioja", "Madrid", "Murcia", "Navarra", "País Vasco")

valores_comunidades <- c("Comunidad.AutónomaAndalucía","Comunidad.AutónomaAragón", "Comunidad.AutónomaAsturias", "Comunidad.AutónomaCantabria", "Comunidad.AutónomaCastilla.y.León", "Comunidad.AutónomaCataluña", "Comunidad.AutónomaExtremadura", "Comunidad.AutónomaGalicia", "Comunidad.AutónomaLa.Rioja", "Comunidad.AutónomaMadrid", "Comunidad.AutónomaMurcia", "Comunidad.AutónomaNavarra", "Comunidad.AutónomaPaís.Vasco")

comunidades <- hashmap()
comunidades[claves_comunidades] <- valores_comunidades

claves_ramas_enseñanza <- c("Artes y Humanidades", "Ciencias", "Ciencias de la Salud", "Ciencias Sociales y Jurídicas", "Ingeniería y Arquitectura")

valores_ramas_enseñanza <- c("Rama.de.enseñanzaArtes.y.Humanidades","Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaIngeniería.y.Arquitectura")

ramas_enseñanza <- hashmap()
ramas_enseñanza[claves_ramas_enseñanza] <- valores_ramas_enseñanza

claves_ambitos_estudio <- c("Arquitectura y construcción", "Artes", "Ciencias de la vida", "Ciencias Físicas, químicas, geológicas", "Derecho", "Economía", "Enfermería y atención a enfermos", "Humanidades", "Informática", "Ingenierías", "Lenguas", "Medicina", "Periodismo e información", "Trabajo social y orientación")

valores_ambitos_estudio <- c("Ámbito.de.estudioArquitectura.y.construcción", "Ámbito.de.estudioArtes", "Ámbito.de.estudioCiencias.de.la.vida", "Ámbito.de.estudioCiencias.Físicas..químicas..geológicas", "Ámbito.de.estudioDerecho", "Ámbito.de.estudioEconomía", "Ámbito.de.estudioEnfermería.y.atención.a.enfermos", "Ámbito.de.estudioHumanidades", "Ámbito.de.estudioInformática", "Ámbito.de.estudioIngenierías", "Ámbito.de.estudioLenguas", "Ámbito.de.estudioMedicina", "Ámbito.de.estudioPeriodismo.e.información", "Ámbito.de.estudioTrabajo.social.y.orientación")
  
ambitos_estudio <- hashmap()
ambitos_estudio[claves_ambitos_estudio] <- valores_ambitos_estudio

valores_ambitos_estudio_ramas_enseñanza <- c("Rama.de.enseñanzaIngeniería.y.Arquitectura", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias", "Rama.de.enseñanzaIngeniería.y.Arquitectura", "Rama.de.enseñanzaArtes.y.Humanidades", "Rama.de.enseñanzaCiencias.de.la.Salud", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas", "Rama.de.enseñanzaCiencias.Sociales.y.Jurídicas")

ambitos_estudio_ramas_enseñanza <- hashmap()
ambitos_estudio_ramas_enseñanza[valores_ambitos_estudio] <- valores_ambitos_estudio_ramas_enseñanza

claves_zonas_nacionalidad <- c("Asia y Oceanía", "EEUU y Canadá", "España", "Norte de África", "Resto de África", "Resto de Europa", "Unión Europea")

valores_zonas_nacionalidad <- c("Zona.de.nacionalidadAsia.y.Oceanía", "Zona.de.nacionalidadEEUU.y.Canadá", "Zona.de.nacionalidadEspaña", "Zona.de.nacionalidadNorte.de.África", "Zona.de.nacionalidadResto.de.África", "Zona.de.nacionalidadResto.de.Europa", "Zona.de.nacionalidadUnión.Europea")

zonas_nacionalidad <- hashmap()
zonas_nacionalidad[claves_zonas_nacionalidad] <- valores_zonas_nacionalidad


```

### 3.3. Funciones auxiliares

```{r}

binary_encode <- function(data, variable, category1, category2) {
  # Crear una nueva columna con la codificación binaria
  data[[variable]] <- ifelse(data[[variable]] == category1, 0, 1)

  # Devolver el conjunto de datos modificado
  return(data)
}
```

```{r}

agregar_datos_pca <- function(data, df_indices, nombre_columna, prefijo_pca) {

  # Obtener el nombre de la comunidad y la fila correspondiente
  valor <- data[[nombre_columna]]
  fila <- df_indices[df_indices$Variable == valor, ]

  # Verificar si se encontró la fila
  if (nrow(fila) > 0) {
    # Extraer los valores de PCA de la fila
    valores_pca <- fila[, grepl("^PCA", colnames(fila))]

    colnames(valores_pca) <- paste0(prefijo_pca, colnames(valores_pca))

    # Agregar las columnas de PCA al dataframe de datos
    data_con_pca <- cbind(data, valores_pca)
    
    data_con_pca <- data_con_pca[, !colnames(data_con_pca) %in% nombre_columna, drop = FALSE]

    return(data_con_pca)
  } else {
    cat("No se encontró la fila correspondiente para el valor:", valor, "\n")
    return(NULL)
  }
}
```

```{r}

adaptar_dataframe <- function(df){
  
  df_nivel <- binary_encode(df, "Forma.de.admisión", "PAU", "FP")
  
  if(!has_key(comunidades, df_nivel$Comunidad.Autónoma)){
    cat("Posibles valores para Comunidad.Autónoma:", paste(keys(comunidades), collapse = ", "))
    stop("Asígnele un valor válido a Comunidad.Autónoma")
  }
  df_nivel$Comunidad.Autónoma <- comunidades[df_nivel$Comunidad.Autónoma]
  
  if (!has_key(ambitos_estudio, df_nivel$Ámbito.de.estudio)) {
    cat("Posibles valores para Ámbito.de.estudio:", paste(keys(ambitos_estudio), collapse = ", "))
    stop("Asígnele un valor válido a Ámbito.de.estudio")
  }
  df_nivel$Ámbito.de.estudio <- ambitos_estudio[[df_nivel$Ámbito.de.estudio]]
  df_nivel$Rama.de.enseñanza <- ambitos_estudio_ramas_enseñanza[[df_nivel$Ámbito.de.estudio]]
  
  if (!has_key(zonas_nacionalidad, df_nivel$Zona.de.nacionalidad)) {
    cat("Posibles valores para Zona.de.nacionalidad:", paste(keys(zonas_nacionalidad), collapse = ", "))
    stop("Asígnele un valor válido a Zona.de.nacionalidad")
  }
  df_nivel$Zona.de.nacionalidad <- zonas_nacionalidad[[df_nivel$Zona.de.nacionalidad]]

  df_pca_comunidad <- agregar_datos_pca(df_nivel, data, "Comunidad.Autónoma", "Comunidad.")
  df_pca_rama_enseñanza <- agregar_datos_pca(df_pca_comunidad, data, "Rama.de.enseñanza", "Rama.")
  df_pca_ambito_estudio <- agregar_datos_pca(df_pca_rama_enseñanza, data, "Ámbito.de.estudio", "Ámbito.")
  df_pca_zona_nacionalidad <- agregar_datos_pca(df_pca_ambito_estudio, data, "Zona.de.nacionalidad", "Zona.de.nacionalidad.")
  
  return(df_pca_zona_nacionalidad)
}
```

### 3.4. Input del usuario

```{r}
nuevos_datos_rf <- data.frame(
    Comunidad.Autónoma = "Andalucía",
    Forma.de.admisión = "PAU",
    Ámbito.de.estudio = "Economía",
    Zona.de.nacionalidad = "España"
)

head(nuevos_datos_rf)
```

```{r}

df_prediccion <- adaptar_dataframe(nuevos_datos_rf)
head(df_prediccion)
```

### 3.5. Predicciones sobre modelos entrenados con validación cruzada

#### 3.5.1. Predicciones sobre Random Forest

```{r}

predicciones <- predict(model_rf, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

#### 3.5.2. Predicciones sobre Decision Tree

```{r}

predicciones <- predict(model_tree, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

### 3.6. Predicciones sobre modelos entrenados con partición de datos 80/20

#### 3.6.1. Predicciones sobre Random Forest

```{r}

predicciones <- predict(model_rf_alternative, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)
```

#### 3.6.2. Predicciones sobre Decision Tree

```{r}

predicciones <- predict(model_tree_alternative, newdata = df_prediccion)

# Imprimir las predicciones
print(predicciones[1]*14)

```

#### 3.6.1. Predicciones sobre LightLGB

```{r}

data_prediction <- as.matrix(df_prediccion)
predicciones <- predict(model_lgb_alternative, data_prediction)


print(predicciones[1]*14)
```
